[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "just a compilation of my academic and personal writing",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nCausality in the Machine Learning Realm\n\n\n\n\n\n\nShamanth Kuthpadi S.\n\n\nJul 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision Trees for Classification\n\n\n\n\n\n\nShamanth Kuthpadi S.\n\n\nMay 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecurrent Neural Networks: Unveiling Sequential Power\n\n\n\n\n\n\nShamanth Kuthpadi S.\n\n\nJan 16, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/011624_rnn/index.html",
    "href": "posts/011624_rnn/index.html",
    "title": "Recurrent Neural Networks: Unveiling Sequential Power",
    "section": "",
    "text": "In the realm of deep learning, vanilla feed-forward neural networks fall short when dealing with sequential data. Sequential information can be best illustrated by text. The context of each word in a sentence is semantically dependent on the words that came before it. Preserving and retaining this information is a short-coming of a typical feed-forward neural net.\nRNNs, on the other hand, allow us to remember and use previous inputs for future predictions. To understand how, let us dive into the architecture and inner workings of these networks.\n\n\nThe Architecture\n\nAn extremely simple model of the RNN architecture\nFrom an eagle’s eye view of RNNs, we can begin to form some intuition in regard to how a temporal characteristic is introduced to sequential data.\nWe can think of the recurrence shown with h as an unrolling through time. Each step carries information from previous steps to make predictions on the current input. Hence, as the network processes each input from the input vector, h evolves. This evolution is the driving factor in every RNN and also the key insight as to how RNNs preserve temporal attributes.\n\n\n\n\nRNN close up\n\n\nThe diagram above is a visual unrolling of the recurrence shown in the eagle’s eye perspective. Note that g is the activation function that provides non-linearity in our neural network. Usually, for RNNs, the most common activation function is the tanh function.\n\nh is the hidden state\n\nx is the input vector\n\ny is the output vector\n\nWeight matrices are also assigned for the inputs, hidden states, and outputs at every layer. These weight matrices are represented as W with subscripts i, h, and o (respectively).\nNote that these weights only need to be initialized once.\n\n\n\nThe progression from hidden state to hidden state is as follows:\n\nMatrix multiplication of the input weight matrix with the input (1)\n\nMatrix multiplication of the hidden state weight matrix with the previous hidden state (2)\n\n\nand (2) are added and fed into the activation function, which in our case is tanh\n\n\n\nRecurrent Neural Networks offer a dynamic solution for tasks requiring sequential and temporal understanding, making them indispensable in various applications."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "If any of what I do interests you, get in touch."
  },
  {
    "objectID": "contact.html#get-in-touch",
    "href": "contact.html#get-in-touch",
    "title": "Contact",
    "section": "Get in Touch",
    "text": "Get in Touch\nYou can reach me through the following channels:\n\nEmail: shamanth.kuthpadi@gmail.com\nLinkedIn: Shamanth Kuthpadi\nGitHub: shamanth-kuthpadi"
  },
  {
    "objectID": "contact.html#contact-form",
    "href": "contact.html#contact-form",
    "title": "Contact",
    "section": "Contact Form",
    "text": "Contact Form\n\nName: \nEmail: \nMessage:\n\n\n\nSend"
  },
  {
    "objectID": "contact.html#response-time",
    "href": "contact.html#response-time",
    "title": "Contact",
    "section": "Response Time",
    "text": "Response Time\nI typically respond to emails within 24-48 hours during weekdays. For urgent matters, please use the direct email contact."
  },
  {
    "objectID": "posts/052324_decision_trees/index.html",
    "href": "posts/052324_decision_trees/index.html",
    "title": "Decision Trees for Classification",
    "section": "",
    "text": "Before we begin to analyze and dissect the functional structure of Decision Trees (also referred to as Classification Trees), it is critical to motivate its applications in the machine learning world.\nIn general, many machine learning models tend to be obscure in how exactly they learn from data. Although the algorithms behind these models are well studied and have a vast literature, choices made within the learning process are still not well defined for a human examiner. In contrast, decision trees are extremely interpretable as the choices made by the algorithm are conditionally formulated.\nConditionally formulated, in the context of Decision Trees, means that the algorithm can be described as a series of if-else statements that test different attributes of an instance to ultimately produce a classification.\nAssume we have trained a Decision Tree as follows:\n\n\n\nImage | Abid Ali Awan\n\n\nThe tree structure of the model allows us to characterize a few key traits:\n\nEach non-leaf node tests the value of a given attribute\n\nEach leaf node represents a classification\n\nEach branch of a node, i, indicates one possible value of the attribute tested in i\n\nThe path from the root node to a leaf node defines a classification rule\n\nLet us assume we want to classify a new instance:\n\\[x = \\{Age: 34, Weight: 70 \\, \\text{kgs}, Smoker: no\\}\\]\nThe root node is where we always begin the traversal. We go through each branch of Age and check to see if Age satisfies the condition. Observe that Age satisfies the last branch (from the left) because \\(34 &gt; 30\\). Then we test if x is a smoker. Our data indicates that x is in fact not a smoker and so we classify x as Low Risk.\nOne thing to note is that we never tested Weight for this instance — this is ok! This is a common possibility of a trained Decision Tree.\n\n\nTraining\nThus far we have discussed how to use a trained Decision Tree to make classifications. But, in order to truly understand the implications that underly these models, we should also take a dive into the actual training process.\n\nFind the best attribute\nImagine we have a dataset with m attributes for each instance. The first step would be to find the best attribute to test. To do this, we need to define a criterion that will allow us to measure how informative testing on a particular attribute will be.\nThere are many variations of criterions, but for the purposes of simplicity, we will focus on Information Gain.\nBefore we introduce Information Gain, it is crucial that we deterministically represent what exactly information of a dataset is. In the context of Decision Trees, information of a dataset is more commonly referred to as the entropy of that dataset. To better illustrate what entropy is, let us utilize an example:\nDataset = {\n  \"Amanda\": \"iPhone\",\n  \"John\": \"iPhone\",\n  \"Sam\": \"Blackberry\",\n  \"Robert\": \"iPhone\",\n  \"Ruby\": \"Blackberry\",\n  \"Shirley\": \"iPhone\"\n}\nThere are two unique classes — iPhone and Blackberry — for which we need to find the probabilities for. This step is a simple counting problem:\n\\[P(\\text{iPhone}) = \\frac{\\# \\text{ of instances with class iPhone}}{\\# \\text{ of instances}} = \\frac{4}{6} = \\tfrac{2}{3}\\]\n\\[P(\\text{Blackberry}) = \\frac{2}{6} = \\tfrac{1}{3}\\]\nFrom here we use the formula for information gain provided below.\n\\[I(p_1, p_2, ... , p_n) = -p_1 \\log(p_1) - p_2 \\log(p_2) - \\dots - p_n \\log(p_n)\\]\nIn our case \\(n=2\\), because there are only two unique classes and \\(p_1 = \\tfrac{2}{3}\\) while \\(p_2 = \\tfrac{1}{3}\\). Thus, we end up with an entropy of:\n\\[I\\left(\\tfrac{2}{3}, \\tfrac{1}{3}\\right) = -\\tfrac{2}{3} \\log\\left(\\tfrac{2}{3}\\right) - \\tfrac{1}{3} \\log\\left(\\tfrac{1}{3}\\right)\\]\nWe can now start to form an intuition as to what exactly entropy is telling us about the dataset.\nEntropy tells us how heterogeneous our dataset is.\nNote that heterogeneous means “how mixed up is our data — particularly the class labels.” So, when making predictions about a certain class, we would like the data to be as homogeneous as possible.\nImagine having 5 apples and 5 oranges in a bag (very heterogeneous, not homogeneous). Would you be able to confidently predict what fruit you will get if you blindly choose? Probably not.\nAlternatively, if we had 9 apples and 1 orange in a bag (very homogeneous, not too heterogeneous), it becomes easier to predict that apples would be the fruit you will get.\nConsequently:\n\nLower entropy → more homogeneous → more informative the dataset is about a particular class.\n\n\n\n\n\nHow exactly does this tie into Information Gain?\nThe idea is straightforward: we want to measure how much information we would gain if we were to split on a certain attribute. Once again, let us use an example.\n\n\n\nexample table\n\n\nImagine we choose to split on the attribute X. We would split into two branches — one for \\((X = 1)\\) and \\((X = 0)\\) each.\nWithin the branch \\((X = 1)\\) we will have 2 instances of class I and one instance of class II. Thus, our entropy will be:\n\\[I[X](\\tfrac{2}{3}, \\tfrac{1}{3}) = -\\tfrac{2}{3} \\log\\left(\\tfrac{2}{3}\\right) - \\tfrac{1}{3} \\log\\left(\\tfrac{1}{3}\\right)\\]\nThe information gain will consequently be defined as the original entropy prior to the split minus the entropy after the split:\n\\[IG = I[\\text{original}] - I[X]\\]\n\nOk, thus far, we have defined what a decision tree is and also presented a criterion to measure information gained from splitting based on an attribute.\nBut how do we actually utilize this? On a high level, we recurse the dataset:\n\nStart with the initial dataset, find the optimal attribute (in our case, optimal means the attribute with the highest information gain).\n\nSplit on the attribute, \\(X\\), and create sub-branches, one for each value \\(X\\) can take.\n\nEach sub-branch will have a partitioned version of the original dataset \\(D\\). Use the partitioned dataset, \\(PD\\), as the new dataset!\n\nNow recurse! That’s it.\n\n\nOf course, there are still some concerns that I haven’t and will not cover for the purposes of this article. Some of the most pressing concerns are:\n\nHow do we split on numerical attributes? The method I have described is for categorical attributes where branches are representative of the categories an attribute can take.\n\nWhen to stop recursing? There are many stopping criterions that you should definitely spend time analyzing.\n\nAre there any other criterions I can use as a metric for information? Yes! Feel free to explore them."
  },
  {
    "objectID": "posts/073125_causality/index.html",
    "href": "posts/073125_causality/index.html",
    "title": "Causality in the Machine Learning Realm",
    "section": "",
    "text": "We should first begin by motivating the use cases for causal inference in the world of machine learning (ML). Before we do so, however, it is critical to emphasize the key differences between typical ML algorithms and causal inference.\n\nWhat are the differences?\n\nAssociation vs. Causation\nAs I am sure you have heard many times in a statistics class, association doesn’t imply causation — this is the underlying principle behind why we should care about causal inference.\nA canonical example to illustrate and really bring home this difference between association and causation is to breifly look at a case study that relates chocolate consumption to Nobel prizes. It was shown that higher chocolate consumption increases the chances of winning a Nobel prize. Of course, eating chocolates is not directly causing Nobel prizes — so then what should we make of this correlation?\nJust that. It is simply a correlation because we haven’t ruled out latent or confounding variables that could have caused both chocolate consumption and Nobel prizes. In fact, another recent study has shown that high chocolate consumption probably means you are financially stable and so this would result in better academic facilities.\n\n\n\nWhy causation?\nCausal reasoning is crucial when we want to understand mechanisms, intervene in systems, or make decisions that change outcomes.\nImagine you’re a policymaker deciding whether to invest in a new education program. A traditional ML model might tell you that students who participate in similar programs tend to have higher test scores. But what if these students already had access to better schools or more support at home? In this case, correlation doesn’t help you decide whether the program causes improvement.\nCausal inference lets us answer questions like:\nWhat would have happened if we hadn’t implemented this policy? Will increasing X lead to an increase in Y, holding everything else constant? What’s the effect of this treatment on this outcome? In contrast, standard ML models mostly aim to predict outcomes — not explain them.\n\n\nHow Do We Learn Causal Relationships (aka causal discovery)?\nSince we can’t usually perform controlled experiments in every scenario, we need to learn causality from observational data. This is hard because we only ever observe one reality (e.g., a person either took a drug or didn’t — not both).\nWhile I won’t delve deeply into algorithmic details here, below are some commonly used causal discovery methods:\nPeter-Clark (PC) Algorithm: a constraint-based method that uses conditional independence tests to infer the structure of a causal graph, assuming causal sufficiency and faithfulness Greed Equivalence Search (GES): a score-based approach that searches over equivalence classes of DAGs by greedily adding or removing edges to optimize a score function Linear Non-Gaussian Acyclic Model (LiNGAM): an algorithm designed for linear systems with non-Gaussian noise, which exploits statistical independence to identify the full causal ordering among variables\n\n\nWhen Should You Use Causal Inference?\nCausal inference becomes essential when:\nYou’re making policy decisions or product changes and want to know their effect There’s concern about bias or confounding You need to simulate interventions or counterfactuals Your end-goal is understanding, not just prediction\n\n\nFinal Thoughts\nCausal inference is not a replacement for machine learning — it’s a complement. Predictive models can guide actions, but causal models explain why things happen and help guide what we should do.\nIn a world driven by data, understanding causation helps us move beyond trends and patterns to the underlying mechanisms. It gives us the tools to make better decisions, especially when the stakes are high."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shamanth Kuthpadi S.",
    "section": "",
    "text": "Linkedin\n  \n  \n    \n     github\n  \n  \n    \n     Email\n  \n  \n    \n     ORCID\n  \n\n  \n  \nAI/ML for Healthcare\nMy research focuses on developing advanced AI systems to deepen our understanding of complex biological processes and drive impactful advancements in healthcare. By leveraging causal learning and inference on multimodal data — including the detailed modeling of biological networks like brain connectomes — I aim to reveal fundamental structures and relationships that can guide more accurate diagnostics and innovative therapeutic approaches.\nI am a computer science graduate student at the Manning College of Information and Computer Sciences in UMass Amherst. This summer I am a ML research intern at IOMICS Corporation, where I focus on building automated casual discovery/estimation pipelines and researching Kolmogorov-Arnold Networks (KANs) for their applicability in the unsupervised and supervised domains.\n\n\n\n\n\nNews\n\n\nAugust 2025: Finally “finished” creating my personal website.\n\n\nFebruary 2025: Working under the supervision of Prof. Deepak Ganesan and with Wireless and Sensor Systems Lab to create a multi-modal system for real-time 3D facial animation from physiological signals.\n\n\nJanuary 2025: Working with Mendel.ai to mitigate hallucinations in clinical summarization using synthetic data generation and preference tuning.\n\n\nJanuary 2025: Starting my Master’s in Computer Science at the University of Massachusetts Amherst\n\n\nDecember 2024: Graduated with a Bachelor’s degree in Computer Science from the University of Massachusetts Amherst\n\n\nSeptember 2024: Began my Independent Study in modeling and analyzing structural brain connectomes under the supervision of Cameron Musco\n\n\nJune 2024: Started working as a Machine Learning Research Intern at IOMICS Corporation\n\n\nSeptember 2021: Started my undergraduate degree in Computer Science at the University of Massachusetts Amherst\n\n\n\n\n\nSelected Publications & Current Research\nA Smart Electrode-Integrated Cooling Patch for Motion-Robust ECG Monitoring and Real-Time 3D Facial Animation\n T. Q. Trung, S. K. Seethakantha, Z. Lei, A. Radmehr, P. Nguyen, D. Ganesan\nSubmitted to Nature Sensors\n\nArtificial Intelligence and Discovery Automation: Path to Democratizing Science\n J. Gormley, D. Corkill, E. Hinderer, S. K. Seethakantha, T. Zisk\nSubmitted to International Conference on Systems Biology (ICSB)\n\nAssess-and-Evolve: Scalable Generation of Preference Tuning Data for Alleviating Hallucinations in Medical Summaries\n S. K. Seethakantha, D. Thai, S. Tiwari, V. P. Gudi, S. Mohan, S. Sairaj, W. Zhao, A. Mitra, A. McCallum\nAlmost finished, to be submitted to ACL"
  }
]